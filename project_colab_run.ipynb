{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMlkaJLYIGet",
        "outputId": "2ecefb65-d962-4367-aea2-67467ea309bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'brain_tumor_img_segmentation'...\n",
            "remote: Enumerating objects: 13288, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 13288 (delta 68), reused 132 (delta 63), pack-reused 13149\u001b[K\n",
            "Receiving objects: 100% (13288/13288), 629.63 MiB | 27.01 MiB/s, done.\n",
            "Resolving deltas: 100% (622/622), done.\n",
            "Updating files: 100% (15655/15655), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Oliverluyu/brain_tumor_img_segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3efxxrKSRrw",
        "outputId": "187bdca3-5a2f-41bf-f9ef-05ae271b6343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/brain_tumor_img_segmentation\n",
            "Branch 'exp2_new' set up to track remote branch 'exp2_new' from 'origin'.\n",
            "Switched to a new branch 'exp2_new'\n"
          ]
        }
      ],
      "source": [
        "%cd brain_tumor_img_segmentation\n",
        "!git checkout exp2_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxssN9F_IK06",
        "outputId": "b8e627d7-2e88-48ab-afaa-9ad79ea95167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 328 bytes | 328.00 KiB/s, done.\n",
            "From https://github.com/Oliverluyu/brain_tumor_img_segmentation\n",
            "   3f666fe..8736a3a  exp2_new   -> origin/exp2_new\n",
            "Updating 3f666fe..8736a3a\n",
            "Fast-forward\n",
            " Configs/cls_vanilla_unet_gated.json | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Epoch: 1; train loss: 1.1863; validation loss: 0.5570\n",
            "Validation Accuracy: 79.25%\n",
            "Epoch: 2; train loss: 0.6399; validation loss: 0.6515\n",
            "Validation Accuracy: 74.76%\n",
            "Epoch: 3; train loss: 0.5490; validation loss: 0.5186\n",
            "Validation Accuracy: 79.61%\n",
            "Epoch: 4; train loss: 0.4861; validation loss: 0.4216\n",
            "Validation Accuracy: 84.22%\n",
            "Epoch: 5; train loss: 0.4509; validation loss: 0.3907\n",
            "Validation Accuracy: 85.56%\n",
            "Epoch: 6; train loss: 0.4406; validation loss: 0.4493\n",
            "Validation Accuracy: 83.86%\n",
            "Epoch: 7; train loss: 0.4107; validation loss: 0.3469\n",
            "Validation Accuracy: 87.14%\n",
            "Epoch: 8; train loss: 0.3971; validation loss: 0.3599\n",
            "Validation Accuracy: 87.38%\n",
            "Epoch: 9; train loss: 0.3796; validation loss: 0.3657\n",
            "Validation Accuracy: 86.53%\n",
            "Epoch: 10; train loss: 0.3515; validation loss: 0.3420\n",
            "Validation Accuracy: 87.50%\n",
            "Figure(1000x500)\n",
            "Plot saved to saved_models/model_performance_20240413-150120.png\n",
            "Training of  classification  is finished!!!\n"
          ]
        }
      ],
      "source": [
        "!git pull\n",
        "!python training.py -c Configs/cls_vanilla_unet_gated.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1k + 3k segmentation Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuC4fbwpCxl-",
        "outputId": "15c63765-bf35-48a3-ab25-093bf17f8d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 1; train loss: 0.2269; validation loss: 0.1572\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 2; train loss: 0.0464; validation loss: 0.0394\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 3; train loss: 0.0330; validation loss: 0.0328\n",
            "100% 133/133 [00:46<00:00,  2.87it/s]\n",
            "Epoch: 4; train loss: 0.0283; validation loss: 0.0288\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch: 5; train loss: 0.0254; validation loss: 0.0262\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 6; train loss: 0.0237; validation loss: 0.0256\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch: 7; train loss: 0.0218; validation loss: 0.0247\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 8; train loss: 0.0200; validation loss: 0.0239\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 9; train loss: 0.0178; validation loss: 0.0254\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 10; train loss: 0.0163; validation loss: 0.0238\n",
            "100% 133/133 [00:46<00:00,  2.84it/s]\n",
            "Epoch: 11; train loss: 0.0148; validation loss: 0.0209\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 12; train loss: 0.0137; validation loss: 0.0205\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 13; train loss: 0.0131; validation loss: 0.0207\n",
            "100% 133/133 [00:46<00:00,  2.84it/s]\n",
            "Epoch: 14; train loss: 0.0109; validation loss: 0.0220\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch: 15; train loss: 0.0104; validation loss: 0.0207\n",
            "100% 133/133 [00:46<00:00,  2.84it/s]\n",
            "Epoch: 16; train loss: 0.0091; validation loss: 0.0240\n",
            "100% 133/133 [00:46<00:00,  2.84it/s]\n",
            "Epoch: 17; train loss: 0.0081; validation loss: 0.0236\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 18; train loss: 0.0073; validation loss: 0.0220\n",
            "100% 133/133 [00:46<00:00,  2.84it/s]\n",
            "Epoch: 19; train loss: 0.0073; validation loss: 0.0261\n",
            "100% 133/133 [00:46<00:00,  2.85it/s]\n",
            "Epoch: 20; train loss: 0.0069; validation loss: 0.0252\n",
            "Figure(1000x500)\n",
            "Plot saved to saved_models/model_performance_20240413-153903.png\n",
            "Training of  segmentation  is finished!!!\n"
          ]
        }
      ],
      "source": [
        "!python training.py -c Configs/seg_vanilla_unet.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](saved_models/model_performance_20240413-153903_without_tf_lrn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1k + 3k Segmentation Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_wth_notum.pth_1.png\n",
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_wth_notum.pth_2.png\n",
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_wth_notum.pth_3.png\n",
            "Average IoU for the test set: 0.5995\n",
            "Average F1 Score for the test set: 0.4340\n"
          ]
        }
      ],
      "source": [
        "!python testing.py -c Configs/seg_vanilla_unet.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "picture illustration\n",
        "![Original Image](saved_models/vanilla_unet_best_segmentation_wth_notum.pth_1.png) ![Ground Truth Mask](saved_models/vanilla_unet_best_segmentation_wth_notum.pth_2.png) ![Predicted Mask](saved_models/vanilla_unet_best_segmentation_wth_notum.pth_3.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 328 bytes | 328.00 KiB/s, done.\n",
            "From https://github.com/Oliverluyu/brain_tumor_img_segmentation\n",
            "   3f666fe..8736a3a  exp2_new   -> origin/exp2_new\n",
            "Updating 3f666fe..8736a3a\n",
            "Fast-forward\n",
            " Configs/cls_vanilla_unet_gated.json | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Epoch: 1; train loss: 1.1863; validation loss: 0.5570\n",
            "Validation Accuracy: 79.25%\n",
            "Epoch: 2; train loss: 0.6399; validation loss: 0.6515\n",
            "Validation Accuracy: 74.76%\n",
            "Epoch: 3; train loss: 0.5490; validation loss: 0.5186\n",
            "Validation Accuracy: 79.61%\n",
            "Epoch: 4; train loss: 0.4861; validation loss: 0.4216\n",
            "Validation Accuracy: 84.22%\n",
            "Epoch: 5; train loss: 0.4509; validation loss: 0.3907\n",
            "Validation Accuracy: 85.56%\n",
            "Epoch: 6; train loss: 0.4406; validation loss: 0.4493\n",
            "Validation Accuracy: 83.86%\n",
            "Epoch: 7; train loss: 0.4107; validation loss: 0.3469\n",
            "Validation Accuracy: 87.14%\n",
            "Epoch: 8; train loss: 0.3971; validation loss: 0.3599\n",
            "Validation Accuracy: 87.38%\n",
            "Epoch: 9; train loss: 0.3796; validation loss: 0.3657\n",
            "Validation Accuracy: 86.53%\n",
            "Epoch: 10; train loss: 0.3515; validation loss: 0.3420\n",
            "Validation Accuracy: 87.50%\n",
            "Figure(1000x500)\n",
            "Plot saved to saved_models/model_performance_20240413-150120.png\n",
            "Training of  classification  is finished!!!\n"
          ]
        }
      ],
      "source": [
        "!git pull\n",
        "!python training.py -c Configs/cls_vanilla_unet_gated.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](saved_models/model_performance_20240413-150120_classification.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1k + 3k Segmentation with Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKCVsMgevVZs",
        "outputId": "bfd30a1a-9758-4cad-ef92-c3d9897735bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "applying transfer learning\n",
            "Transferred layer conv1.conv1.0.weight\n",
            "Transferred layer conv1.conv1.0.bias\n",
            "Transferred layer conv1.conv1.1.weight\n",
            "Transferred layer conv1.conv1.1.bias\n",
            "Transferred layer conv1.conv1.1.running_mean\n",
            "Transferred layer conv1.conv1.1.running_var\n",
            "Transferred layer conv1.conv1.1.num_batches_tracked\n",
            "Transferred layer conv1.conv2.0.weight\n",
            "Transferred layer conv1.conv2.0.bias\n",
            "Transferred layer conv1.conv2.1.weight\n",
            "Transferred layer conv1.conv2.1.bias\n",
            "Transferred layer conv1.conv2.1.running_mean\n",
            "Transferred layer conv1.conv2.1.running_var\n",
            "Transferred layer conv1.conv2.1.num_batches_tracked\n",
            "Transferred layer conv2.conv1.0.weight\n",
            "Transferred layer conv2.conv1.0.bias\n",
            "Transferred layer conv2.conv1.1.weight\n",
            "Transferred layer conv2.conv1.1.bias\n",
            "Transferred layer conv2.conv1.1.running_mean\n",
            "Transferred layer conv2.conv1.1.running_var\n",
            "Transferred layer conv2.conv1.1.num_batches_tracked\n",
            "Transferred layer conv2.conv2.0.weight\n",
            "Transferred layer conv2.conv2.0.bias\n",
            "Transferred layer conv2.conv2.1.weight\n",
            "Transferred layer conv2.conv2.1.bias\n",
            "Transferred layer conv2.conv2.1.running_mean\n",
            "Transferred layer conv2.conv2.1.running_var\n",
            "Transferred layer conv2.conv2.1.num_batches_tracked\n",
            "Transferred layer conv3.conv1.0.weight\n",
            "Transferred layer conv3.conv1.0.bias\n",
            "Transferred layer conv3.conv1.1.weight\n",
            "Transferred layer conv3.conv1.1.bias\n",
            "Transferred layer conv3.conv1.1.running_mean\n",
            "Transferred layer conv3.conv1.1.running_var\n",
            "Transferred layer conv3.conv1.1.num_batches_tracked\n",
            "Transferred layer conv3.conv2.0.weight\n",
            "Transferred layer conv3.conv2.0.bias\n",
            "Transferred layer conv3.conv2.1.weight\n",
            "Transferred layer conv3.conv2.1.bias\n",
            "Transferred layer conv3.conv2.1.running_mean\n",
            "Transferred layer conv3.conv2.1.running_var\n",
            "Transferred layer conv3.conv2.1.num_batches_tracked\n",
            "Transferred layer conv4.conv1.0.weight\n",
            "Transferred layer conv4.conv1.0.bias\n",
            "Transferred layer conv4.conv1.1.weight\n",
            "Transferred layer conv4.conv1.1.bias\n",
            "Transferred layer conv4.conv1.1.running_mean\n",
            "Transferred layer conv4.conv1.1.running_var\n",
            "Transferred layer conv4.conv1.1.num_batches_tracked\n",
            "Transferred layer conv4.conv2.0.weight\n",
            "Transferred layer conv4.conv2.0.bias\n",
            "Transferred layer conv4.conv2.1.weight\n",
            "Transferred layer conv4.conv2.1.bias\n",
            "Transferred layer conv4.conv2.1.running_mean\n",
            "Transferred layer conv4.conv2.1.running_var\n",
            "Transferred layer conv4.conv2.1.num_batches_tracked\n",
            "Transferred layer center.conv1.0.weight\n",
            "Transferred layer center.conv1.0.bias\n",
            "Transferred layer center.conv1.1.weight\n",
            "Transferred layer center.conv1.1.bias\n",
            "Transferred layer center.conv1.1.running_mean\n",
            "Transferred layer center.conv1.1.running_var\n",
            "Transferred layer center.conv1.1.num_batches_tracked\n",
            "Transferred layer center.conv2.0.weight\n",
            "Transferred layer center.conv2.0.bias\n",
            "Transferred layer center.conv2.1.weight\n",
            "Transferred layer center.conv2.1.bias\n",
            "Transferred layer center.conv2.1.running_mean\n",
            "Transferred layer center.conv2.1.running_var\n",
            "Transferred layer center.conv2.1.num_batches_tracked\n",
            "Loaded pretrained weights for specified layers.\n",
            "100% 133/133 [00:46<00:00,  2.87it/s]\n",
            "Epoch: 1; train loss: 0.4718; validation loss: 0.3060\n",
            "100% 133/133 [00:45<00:00,  2.91it/s]\n",
            "Epoch: 2; train loss: 0.0627; validation loss: 0.0421\n",
            "100% 133/133 [00:45<00:00,  2.89it/s]\n",
            "Epoch: 3; train loss: 0.0383; validation loss: 0.0360\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 4; train loss: 0.0320; validation loss: 0.0335\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 5; train loss: 0.0291; validation loss: 0.0309\n",
            "100% 133/133 [00:45<00:00,  2.90it/s]\n",
            "Epoch: 6; train loss: 0.0259; validation loss: 0.0287\n",
            "100% 133/133 [00:46<00:00,  2.89it/s]\n",
            "Epoch: 7; train loss: 0.0247; validation loss: 0.0262\n",
            "100% 133/133 [00:46<00:00,  2.87it/s]\n",
            "Epoch: 8; train loss: 0.0236; validation loss: 0.0242\n",
            "100% 133/133 [00:46<00:00,  2.89it/s]\n",
            "Epoch: 9; train loss: 0.0217; validation loss: 0.0238\n",
            "100% 133/133 [00:46<00:00,  2.87it/s]\n",
            "Epoch: 10; train loss: 0.0206; validation loss: 0.0221\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch: 11; train loss: 0.0190; validation loss: 0.0236\n",
            "100% 133/133 [00:45<00:00,  2.90it/s]\n",
            "Epoch: 12; train loss: 0.0184; validation loss: 0.0203\n",
            "100% 133/133 [00:46<00:00,  2.89it/s]\n",
            "Epoch: 13; train loss: 0.0178; validation loss: 0.0204\n",
            "100% 133/133 [00:46<00:00,  2.86it/s]\n",
            "Epoch: 14; train loss: 0.0164; validation loss: 0.0195\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 15; train loss: 0.0159; validation loss: 0.0201\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 16; train loss: 0.0152; validation loss: 0.0187\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 17; train loss: 0.0147; validation loss: 0.0214\n",
            "100% 133/133 [00:46<00:00,  2.89it/s]\n",
            "Epoch: 18; train loss: 0.0134; validation loss: 0.0207\n",
            "100% 133/133 [00:46<00:00,  2.88it/s]\n",
            "Epoch: 19; train loss: 0.0139; validation loss: 0.0200\n",
            "100% 133/133 [00:46<00:00,  2.87it/s]\n",
            "Epoch: 20; train loss: 0.0126; validation loss: 0.0188\n",
            "Figure(1000x500)\n",
            "Plot saved to saved_models/model_performance_20240413-234842.png\n",
            "Training of  segmentation  is finished!!!\n"
          ]
        }
      ],
      "source": [
        "!python training.py -c Configs/seg_vanilla_unet_transLearn_cls_layer.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](saved_models/model_performance_20240413-234842_with_tf_lrn_layer.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1k + 3k Segmentation Result with Transfer Learning from Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_1.png\n",
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_2.png\n",
            "Saved visualization to saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_3.png\n",
            "Average IoU for the test set: 0.6506\n",
            "Average F1 Score for the test set: 0.4775\n"
          ]
        }
      ],
      "source": [
        "!python testing.py -c Configs/seg_vanilla_unet_transLearn_cls_layer.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "picture illustration\n",
        "![Original Image](saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_1.png) ![Ground Truth Mask](saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_2.png) ![Predicted Mask](saved_models/vanilla_unet_best_segmentation_with_transLearn_cls_layer.pth_3.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTDmTrQ8vbLh"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
